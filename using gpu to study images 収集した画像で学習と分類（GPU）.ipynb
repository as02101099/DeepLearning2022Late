{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as02101099/DeepLearning2022Late/blob/main/using%20gpu%20to%20study%20images%20%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E7%94%BB%E5%83%8F%E3%81%A7%E5%AD%A6%E7%BF%92%E3%81%A8%E5%88%86%E9%A1%9E%EF%BC%88GPU%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 収集した画像をColabにUPして学習させ、それをもとに分類させる"
      ],
      "metadata": {
        "id": "bR-9FjxoV27Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ファイルのフォルダを準備する"
      ],
      "metadata": {
        "id": "1w8UjxH4WMwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('sample', exist_ok=True) # 分類対象の画像のフォルダを作成\n",
        "os.makedirs('output/dog/sample', exist_ok=True) # 犬と判定された時の置き場所\n",
        "os.makedirs('output/cat/sample', exist_ok=True) # 猫と判定された時の置き場所\n",
        "os.makedirs('img/deep_learning/dog', exist_ok=True) # 犬の学習用の収集画像\n",
        "os.makedirs('img/deep_learning/cat', exist_ok=True) # 猫の学習用の収集画像\n"
      ],
      "metadata": {
        "id": "h6iDc4ZjWETO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 必要なライブラリをimport"
      ],
      "metadata": {
        "id": "n6xzpB_vYMgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "t_-YKvI-Xk0G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分類（クラス）の名前をフォルダ名（dog, cat）から引用する"
      ],
      "metadata": {
        "id": "argET_MTZfWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"img/deep_learning\" # dogとcatフォルダがある場所\n",
        "folders = os.listdir(path)\n",
        "# ２つのパスからフォルダ名を抜き出す\n",
        "classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n",
        "print(classes)\n",
        "n_classes = len(classes)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIEMQ4kKZGRp",
        "outputId": "2abdc497-431b-4bae-b466-f75db0ec67da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 画像を読み込みリサイズ、整形する"
      ],
      "metadata": {
        "id": "NeNsrmCN9Xxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像とラベルのための配列\n",
        "X = [ ] # 画像（学習データ用の配列）\n",
        "Y = [ ] # ラベル（正解用の配列）\n",
        "\n",
        "# 画像を読み込みつつリサイズする\n",
        "for label, class_name in enumerate(classes):\n",
        "  files = glob.glob( path + \"/\" + class_name + \"/*jpg\" )\n",
        "  for file in files:\n",
        "    img = cv2.imread(file)\n",
        "    img = cv2.resize( img, dsize=(224, 224) )\n",
        "    X.append(img)\n",
        "    Y.append(label)\n",
        "    # 内部ループ終わり\n",
        "# 外部ループ終わり  "
      ],
      "metadata": {
        "id": "_Qq4rOJRahc2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0～255のビットデータ値を、学習のために0～1に変換（正規化）学習精度を上げる"
      ],
      "metadata": {
        "id": "9qc4XiXwEtIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array( X ) # 配列XをNumpy配列に変換\n",
        "X = X.astype('float32') # 小数型に変換\n",
        "X /=255.0\n",
        "# ラベルもnumpyの配列に変換\n",
        "Y = np.array( Y )\n",
        "Y = np_utils.to_categorical( Y, n_classes )"
      ],
      "metadata": {
        "id": "v_RbkNNOAvWf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  整形したデータを学習用とテスト検証用にふりわける"
      ],
      "metadata": {
        "id": "i0Ib8hg1GLkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データ８割、テスト検証用が２割にわける\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2 )\n",
        "# 学習データ８割(画像問題データ)\n",
        "print( X_train.shape )\n",
        "# テストデータ２割(画像問題データ)\n",
        "print( X_test.shape )\n",
        "# 学習データ８割（正解ラベル）\n",
        "print( Y_train.shape )\n",
        "# テストデータ２割（正解ラベル）\n",
        "print( Y_test.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "m3bJwymfGHk5",
        "outputId": "a08fb7ac-b787-4ef7-b0e4-09ccbd6374c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5a54780dbaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習データ８割、テスト検証用が２割にわける\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# 学習データ８割(画像問題データ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# テストデータ２割(画像問題データ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2421\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備したデータを学習させていく"
      ],
      "metadata": {
        "id": "6IzKnXAJLJp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習に必要なライブラリをimport"
      ],
      "metadata": {
        "id": "AIAcU7LbLTmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "M5X4x1poIOh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルのVGG16をアレンジしていく"
      ],
      "metadata": {
        "id": "K4RT8DJLStbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16　入力層を用意する(定義する)\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "# VGG16のインスタンスを作る（最後のsoftmaxの1000層を無効にして省く）\n",
        "base_model = VGG16( weights='imagenet', input_tensor=input_tensor, include_top=False )\n"
      ],
      "metadata": {
        "id": "O1T8W85IMboH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1000分類のsoftmaxを外した代わりに、2つに分類するsoftmax層を追加する"
      ],
      "metadata": {
        "id": "S5HlqHDdWUs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 追加する層の作成\n",
        "top_model = Sequential( ) # ラッピングする層\n",
        "top_model.add( Flatten( input_shape=base_model.output_shape[1:] ) )\n",
        "top_model.add( Dense( n_classes, activation='softmax' ) )\n"
      ],
      "metadata": {
        "id": "yBwuZSkiWPqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最後のSOFTMAXを外したモデル（basemodel）と追加用の2つに分類するSOFTMAX層のモデル（top_mode）をつなげる"
      ],
      "metadata": {
        "id": "CK55jwxsZ_9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model( inputs=base_model.input, outputs=top_model(base_model.output) )"
      ],
      "metadata": {
        "id": "sSr378MOX7r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 時間短縮のために、15層までを外す"
      ],
      "metadata": {
        "id": "1DtsW_OWbJ9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ループしながら15層までを無効にする\n",
        "for layer in model.layers[:15]:\n",
        "  layer.trainable = False # 15層までは学習しない\n",
        "# ループ終わり\n",
        "print( '# laers=', len(model.layers) ) # モデルの層の数を表示"
      ],
      "metadata": {
        "id": "eKc2yIOPa4ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習モデルをコンパイルする"
      ],
      "metadata": {
        "id": "dt9_0S3Fcd7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失はクロスエントロピー法で算出、最適化はADAM、指標は精度でみる\n",
        "model.compile( loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "08PayTi0cRVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### コンパイルしたモデルを表示"
      ],
      "metadata": {
        "id": "aR8qtmlHeWtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary( )"
      ],
      "metadata": {
        "id": "dP2S05goegbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コンパイルしたモデルで収集した画像データを学習させる"
      ],
      "metadata": {
        "id": "PLhD7l4TfU9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( X_train, Y_train, epochs=20, batch_size=16 )"
      ],
      "metadata": {
        "id": "UTO8s_NXejvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習の成果を指標(accuracy)で確認"
      ],
      "metadata": {
        "id": "B2Af7xGPhkSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate( X_test, Y_test, batch_size=16 )"
      ],
      "metadata": {
        "id": "DX2n1Urlf8qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 作成した学習モデルとクラス分類名を保存"
      ],
      "metadata": {
        "id": "i7rfKBldihgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# vクラス分類の保存\n",
        "pickle.dump( classes, open('classes.sav', 'wb') ) # オブジェクトをバイナリファイルで保存\n",
        "# 学習モデルの保存\n",
        "model.save( 'cnn.h5' )"
      ],
      "metadata": {
        "id": "6yG2xq0Jh8Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保存したクラス分類と学習モデルを読み込んで使う"
      ],
      "metadata": {
        "id": "oRLpcYJVkBIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリのimport\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import cv2\n",
        "import glob"
      ],
      "metadata": {
        "id": "ViRPDNUrjHQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ファイルを読み込んでオブジェクトとしてよみがえらせる"
      ],
      "metadata": {
        "id": "NvvzuCn6k0rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('cnn.h5')\n",
        "classes = pickle.load( open( 'classes.sav', 'rb' ) )"
      ],
      "metadata": {
        "id": "nW_8pUZWkxUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sample画像を読み込む"
      ],
      "metadata": {
        "id": "UA4xx9aMTk7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob( 'sample/*' )\n",
        "print(files)"
      ],
      "metadata": {
        "id": "TOfbs96wU1gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ファイルパスから画像を読み込み、学習モデルに判定させ、該当するoutputフォルダにコピーを書き込む"
      ],
      "metadata": {
        "id": "B7WoO8flVgvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files: #ファイルの数だけループ\n",
        "  img = cv2.imread(file) # 画像データを読み込み\n",
        "  # 判定のためにimgを加工したimg2を作る\n",
        "  img2 = cv2.resize( img, dsize=(224, 224) ) # (224, 224)にリサイズ\n",
        "  img2 = img2.astype('float32')\n",
        "  img2 = img2/255.0 # 0.0～255.0 だったデータを0.0～1.0に変換\n",
        "  img2 = img2[None, ...] # 1次元配列に変換\n",
        "  # 正規化したデータを判定\n",
        "  result = model.predict(img2)\n",
        "  print(result) # 画面に生で出力\n",
        "  # 確率が高いクラスを取得\n",
        "  pred = result.argmax( )\n",
        "  print( pred, str(classes[pred]) )\n",
        "  # 判定したクラス分類のフォルダのほうに、画像データを書き込む\n",
        "  cv2.imwrite( 'output/' + str(classes[pred]) + '/' + file, img )\n",
        "# ループ終わり"
      ],
      "metadata": {
        "id": "KfYKrEJYVJNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"executed completly\")"
      ],
      "metadata": {
        "id": "WXXGEiXV8PGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}